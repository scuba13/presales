import OpenAI from 'openai';
import { logger } from '../config/logger';
import fs from 'fs/promises';
import path from 'path';
import { createReadStream } from 'fs';
import { File } from 'node:buffer';

// Polyfill para Node 18
if (typeof globalThis.File === 'undefined') {
  (globalThis as any).File = File;
}

// Tipos (compat√≠veis com ClaudeService)
export interface ProjectAnalysis {
  scope: string;
  coreFunctionalities: string[];
  integrations: string[];
  nonFunctionalRequirements: string[];
  complexity: 'low' | 'medium' | 'high';
  risks: string[];
}

export interface TeamEstimation {
  teamComposition: { role: string; quantity: number }[];
  monthlyAllocation: { role: string; hoursPerMonth: number[] }[];
  projectDuration: number;
  phases: { name: string; effortPercentage: number }[];
}

export interface Schedule {
  sprints: { number: number; deliverables: string[] }[];
  dependencies: { task: string; dependsOn: string[] }[];
  milestones: { name: string; date: string }[];
  riskBuffer: number;
}

export interface CompleteAnalysis {
  analysis: ProjectAnalysis;
  teamEstimation: TeamEstimation;
  schedule: Schedule;
}

export class OpenAIService {
  private client: OpenAI;
  private model: string;

  constructor(model?: string) {
    const apiKey = process.env.OPENAI_API_KEY;

    if (!apiKey) {
      throw new Error('OPENAI_API_KEY n√£o configurada no ambiente');
    }

    this.client = new OpenAI({
      apiKey: apiKey,
    });

    // Modelo padr√£o se n√£o for especificado
    this.model = model || 'gpt-4-turbo-preview';

    logger.info(`‚úÖ OpenAI Service inicializado com modelo: ${this.model}`);
  }

  /**
   * Converte arquivo para base64
   */
  private async fileToBase64(filePath: string): Promise<string> {
    const buffer = await fs.readFile(filePath);
    return buffer.toString('base64');
  }

  /**
   * Converte MIME type para formato OpenAI
   */
  private getImageFormat(mimetype: string): string {
    const mimeToFormat: { [key: string]: string } = {
      'image/png': 'png',
      'image/jpeg': 'jpeg',
      'image/jpg': 'jpeg',
      'image/gif': 'gif',
      'image/webp': 'webp',
    };
    return mimeToFormat[mimetype] || 'jpeg';
  }

  /**
   * Prepara conte√∫do dos arquivos para a API OpenAI
   */
  private async prepareFilesContent(files: { path: string; mimetype: string }[]): Promise<any[]> {
    const content: any[] = [];

    for (const file of files) {
      const ext = path.extname(file.path).toLowerCase();

      // Para imagens, usar vision com base64
      if (file.mimetype.startsWith('image/')) {
        const base64 = await this.fileToBase64(file.path);
        content.push({
          type: 'image_url',
          image_url: {
            url: `data:${file.mimetype};base64,${base64}`,
            detail: 'high',
          },
        });
      }
      // Para PDFs e outros documentos, fazer upload para OpenAI e usar file_id
      else if (file.mimetype === 'application/pdf' || file.mimetype.includes('text')) {
        logger.info(`üì§ Fazendo upload do arquivo ${path.basename(file.path)} para OpenAI...`);

        const uploaded = await this.client.files.create({
          file: createReadStream(file.path),
          purpose: 'user_data',
        });

        logger.info(`‚úÖ Arquivo enviado com file_id: ${uploaded.id}`);

        content.push({
          type: 'file',
          file: {
            file_id: uploaded.id,
          },
        });
      }
    }

    return content;
  }

  /**
   * Faz requisi√ß√£o √† API OpenAI com retry
   */
  private async callAPI(messages: any[], responseFormat?: any): Promise<string> {
    const maxRetries = 3;
    let lastError: Error | null = null;

    for (let attempt = 1; attempt <= maxRetries; attempt++) {
      try {
        logger.info(`üì° Chamando OpenAI API (tentativa ${attempt}/${maxRetries})`);

        // Modelos o1 e GPT-5 t√™m par√¢metros diferentes
        const isO1Model = this.model.startsWith('o1');
        const isGPT5Model = this.model.startsWith('gpt-5');
        const isReasoningModel = isO1Model || isGPT5Model;

        // Para modelos o1/GPT-5: combinar system com user prompt (n√£o suportam role 'system')
        let processedMessages = messages;
        if (isReasoningModel && messages.length > 0 && messages[0].role === 'system') {
          logger.info(`üîÑ Modelo ${isO1Model ? 'o1' : 'GPT-5'} detectado - combinando system prompt com user prompt`);
          const systemContent = messages[0].content;
          const userMessage = messages[1];

          // Para o1: apenas texto (n√£o suporta imagens)
          // Para GPT-5: suporta imagens e documentos
          if (isO1Model) {
            // Extrair apenas texto para o1
            let userText = '';
            if (typeof userMessage.content === 'string') {
              userText = userMessage.content;
            } else if (Array.isArray(userMessage.content)) {
              logger.info(`üìã User message tem ${userMessage.content.length} blocos`);
              const textBlocks = userMessage.content.filter((block: any) => block.type === 'text');
              logger.info(`üìù Blocos de texto: ${textBlocks.length}`);
              userText = textBlocks.map((block: any) => block.text).join('\n\n');
            }

            // Combinar system + user como texto puro (o1 s√≥ aceita texto)
            const combinedContent = `${systemContent}\n\n${userText}`;
            processedMessages = [
              { role: 'user', content: combinedContent },
              ...messages.slice(2),
            ];
            logger.info(`‚úÖ Content length: ${combinedContent.length} caracteres`);
          } else {
            // GPT-5: manter imagens e documentos
            const combinedContent = typeof userMessage.content === 'string'
              ? `${systemContent}\n\n${userMessage.content}`
              : [{ type: 'text', text: systemContent }, ...userMessage.content];

            processedMessages = [
              { role: 'user', content: combinedContent },
              ...messages.slice(2),
            ];
          }

          logger.info(`‚úÖ Mensagens processadas: ${processedMessages.length} mensagem(ns)`);
          logger.info(`‚úÖ Primeira mensagem role: ${processedMessages[0].role}`);
        }

        const requestParams: any = {
          model: this.model,
          messages: processedMessages,
        };

        // Adicionar par√¢metros baseado no modelo
        if (isReasoningModel) {
          // Modelos o1 e GPT-5 n√£o suportam temperature nem response_format
          requestParams.max_completion_tokens = 16000;
        } else {
          // Modelos tradicionais (GPT-4, GPT-3.5)
          requestParams.temperature = 0.3;
          requestParams.max_tokens = 4096;
          requestParams.response_format = responseFormat || { type: 'text' };
        }

        const response = await this.client.chat.completions.create(requestParams);

        logger.info(`üìä Response choices: ${response.choices?.length || 0}`);
        if (response.choices?.[0]) {
          logger.info(`üìä Message role: ${response.choices[0].message?.role}`);
          logger.info(`üìä Content length: ${response.choices[0].message?.content?.length || 0}`);
          logger.info(`üìä Finish reason: ${response.choices[0].finish_reason}`);
        }

        const content = response.choices[0]?.message?.content;

        if (!content) {
          logger.error('‚ùå Resposta vazia recebida:', JSON.stringify(response, null, 2));
          throw new Error('OpenAI retornou resposta vazia');
        }

        logger.info('‚úÖ Resposta recebida da OpenAI');
        return content;
      } catch (error: any) {
        lastError = error;
        logger.warn(`‚ö†Ô∏è Erro na tentativa ${attempt}: ${error.message}`);

        if (attempt < maxRetries) {
          await new Promise((resolve) => setTimeout(resolve, 2000 * attempt));
        }
      }
    }

    throw lastError || new Error('Falha ao chamar OpenAI API');
  }

  /**
   * PROMPT 1: An√°lise de Escopo do Projeto
   */
  async analyzeProjectScope(
    files: { path: string; mimetype: string }[],
    additionalContext?: string
  ): Promise<ProjectAnalysis> {
    logger.info('üîç Iniciando an√°lise de escopo com OpenAI...');

    const filesContent = await this.prepareFilesContent(files);

    const systemPrompt = `Voc√™ √© um analista de projetos especialista em software. Analise os documentos fornecidos e extraia informa√ß√µes estruturadas sobre o projeto.

Retorne APENAS um JSON v√°lido (sem markdown, sem \`\`\`json) com esta estrutura:
{
  "scope": "descri√ß√£o do escopo em 2-3 frases",
  "coreFunctionalities": ["funcionalidade 1", "funcionalidade 2", ...],
  "integrations": ["integra√ß√£o 1", "integra√ß√£o 2", ...],
  "nonFunctionalRequirements": ["requisito 1", "requisito 2", ...],
  "complexity": "low|medium|high",
  "risks": ["risco 1", "risco 2", ...]
}`;

    const contextText = additionalContext
      ? `\n\n**CONTEXTO ADICIONAL FORNECIDO PELO USU√ÅRIO:**\n${additionalContext}\n\n`
      : '';

    const userPrompt = `Analise os documentos fornecidos e extraia:${contextText}
1. Escopo geral do projeto
2. Funcionalidades principais
3. Integra√ß√µes necess√°rias
4. Requisitos n√£o funcionais (performance, seguran√ßa, etc)
5. Complexidade (baixa, m√©dia, alta)
6. Riscos identificados`;

    const messages: any[] = [
      { role: 'system', content: systemPrompt },
      {
        role: 'user',
        content: [{ type: 'text', text: userPrompt }, ...filesContent],
      },
    ];

    const response = await this.callAPI(messages, { type: 'json_object' });
    const analysis = JSON.parse(response);

    logger.info(`‚úÖ An√°lise conclu√≠da - Complexidade: ${analysis.complexity}`);
    return analysis;
  }

  /**
   * PROMPT 2: Estimativa de Equipe
   */
  async estimateTeam(analysis: ProjectAnalysis): Promise<TeamEstimation> {
    logger.info('üë• Estimando composi√ß√£o de equipe com OpenAI...');

    const systemPrompt = `Voc√™ √© um gerente de projetos especialista em dimensionamento de equipes de software.

Com base na an√°lise do projeto, sugira a composi√ß√£o da equipe e aloca√ß√£o mensal.

Retorne APENAS um JSON v√°lido (sem markdown, sem \`\`\`json) com esta estrutura:
{
  "teamComposition": [
    { "role": "Tech Lead", "quantity": 1 },
    { "role": "Backend Developer", "quantity": 2 }
  ],
  "monthlyAllocation": [
    { "role": "Tech Lead", "hoursPerMonth": [160, 160, 160, 80, 80, 40] },
    { "role": "Backend Developer", "hoursPerMonth": [160, 160, 160, 160, 120, 80] }
  ],
  "projectDuration": 6,
  "phases": [
    { "name": "Discovery", "effortPercentage": 10 },
    { "name": "Development", "effortPercentage": 60 },
    { "name": "Testing", "effortPercentage": 20 },
    { "name": "Deployment", "effortPercentage": 10 }
  ]
}

IMPORTANTE:
- hoursPerMonth deve ter o n√∫mero de posi√ß√µes igual a projectDuration
- Use roles padr√£o: Tech Lead, Backend Developer, Frontend Developer, QA Engineer, DevOps Engineer, UX/UI Designer
- A aloca√ß√£o deve diminuir nas fases finais
- projectDuration: voc√™ decide livremente baseado na complexidade (pode ser 1 m√™s, 6 meses, 24 meses, etc)`;

    const userPrompt = `Com base nesta an√°lise do projeto:

Escopo: ${analysis.scope}
Funcionalidades: ${analysis.coreFunctionalities.join(', ')}
Complexidade: ${analysis.complexity}

Sugira:
1. Composi√ß√£o da equipe (roles e quantidade)
2. Aloca√ß√£o mensal de horas para cada role
3. Dura√ß√£o total do projeto em meses (voc√™ decide livremente baseado na complexidade real)
4. Divis√£o em fases com % de esfor√ßo`;

    const messages = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ];

    const response = await this.callAPI(messages, { type: 'json_object' });
    const estimation = JSON.parse(response);

    logger.info(`‚úÖ Equipe estimada - ${estimation.teamComposition.length} roles`);
    return estimation;
  }

  /**
   * PROMPT 3: Gera√ß√£o de Cronograma
   */
  async generateSchedule(teamEstimation: TeamEstimation): Promise<Schedule> {
    logger.info('üìÖ Gerando cronograma com OpenAI...');

    const systemPrompt = `Voc√™ √© um gerente de projetos especialista em planejamento √°gil.

Com base na estimativa de equipe, crie um cronograma detalhado com sprints.

Retorne APENAS um JSON v√°lido (sem markdown, sem \`\`\`json) com esta estrutura:
{
  "sprints": [
    { "number": 1, "deliverables": ["Setup inicial", "Arquitetura"] },
    { "number": 2, "deliverables": ["Feature X", "Feature Y"] }
  ],
  "dependencies": [
    { "task": "Deploy", "dependsOn": ["Testes completos", "Aprova√ß√£o QA"] }
  ],
  "milestones": [
    { "name": "MVP Ready", "date": "M3" },
    { "name": "Beta Release", "date": "M6" }
  ],
  "riskBuffer": 15
}

IMPORTANTE:
- Criar sprints de 2 semanas
- Dura√ß√£o: ${teamEstimation.projectDuration} meses
- riskBuffer deve ser entre 10-20 (%)`;

    const userPrompt = `Com base nesta estimativa:

Dura√ß√£o: ${teamEstimation.projectDuration} meses
Fases: ${teamEstimation.phases.map((p) => `${p.name} (${p.effortPercentage}%)`).join(', ')}

Crie:
1. Sprints com entregas principais
2. Depend√™ncias entre tarefas
3. Marcos (milestones) importantes
4. Buffer de risco (%)`;

    const messages = [
      { role: 'system', content: systemPrompt },
      { role: 'user', content: userPrompt },
    ];

    const response = await this.callAPI(messages, { type: 'json_object' });
    const schedule = JSON.parse(response);

    logger.info(`‚úÖ Cronograma gerado - ${schedule.sprints.length} sprints`);
    return schedule;
  }

  /**
   * M√©todo orquestrador - An√°lise completa
   */
  async analyzeComplete(
    files: { path: string; mimetype: string }[],
    additionalContext?: string
  ): Promise<CompleteAnalysis> {
    logger.info('üöÄ Iniciando an√°lise completa com OpenAI...');

    const analysis = await this.analyzeProjectScope(files, additionalContext);
    const teamEstimation = await this.estimateTeam(analysis);
    const schedule = await this.generateSchedule(teamEstimation);

    logger.info('‚úÖ An√°lise completa finalizada com OpenAI');

    return {
      analysis,
      teamEstimation,
      schedule,
    };
  }
}
